{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "401b07c8",
   "metadata": {},
   "source": [
    "# Augmentation_8\n",
    "SMOTE-OUT: Alleviate the problem of SMOTE creating meaninglss synthetic examples in dense distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3fdf84d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"./merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3a620c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data\n",
    "y=data['Petting']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24180b8",
   "metadata": {},
   "source": [
    "# Smote-out\n",
    "[Before] Petting: 5 / Non-Petting: 10 --> [After] Petting: 90 / Non-Petting: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4ccc191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/jeony/AppData/Local/Programs/Python/Python311/Lib/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "847e003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2d8ac2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smote_variants.base import NearestNeighborsWithMetricTensor\n",
    "from smote_variants.base import OverSampling\n",
    "from smote_variants.base import coalesce\n",
    "from smote_variants._logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "69604a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "_logger = logger\n",
    "__all__= ['SMOTE_OUT']\n",
    "\n",
    "class SMOTE_OUT(OverSampling):\n",
    "\n",
    "    categories = [OverSampling.cat_extensive,\n",
    "                  OverSampling.cat_metric_learning]\n",
    "\n",
    "    def __init__(self,\n",
    "                 proportion=17.0, # Create 85 more Petting ==1 Data (5*17=85)\n",
    "                 n_neighbors=2,\n",
    "                 *,\n",
    "                 nn_params=None,\n",
    "                 n_jobs=1,\n",
    "                 random_state=None,\n",
    "                 **_kwargs):\n",
    "        \"\"\"\n",
    "        Constructor of the sampling object\n",
    "\n",
    "        Args:\n",
    "            proportion (float): proportion of the difference of n_maj and n_min\n",
    "                                to sample e.g. 1.0 means that after sampling\n",
    "                                the number of minority samples will be equal to\n",
    "                                the number of majority samples\n",
    "            n_neighbors (int): parameter of the NearestNeighbors component\n",
    "            nn_params (dict): additional parameters for nearest neighbor calculations, any\n",
    "                                parameter NearestNeighbors accepts, and additionally use\n",
    "                                {'metric': 'precomputed', 'metric_learning': '<method>', ...}\n",
    "                                with <method> in 'ITML', 'LSML' to enable the learning of\n",
    "                                the metric to be used for neighborhood calculations\n",
    "            n_jobs (int): number of parallel jobs\n",
    "            random_state (int/RandomState/None): initializer of random_state,\n",
    "                                                    like in sklearn\n",
    "        \"\"\"\n",
    "        super().__init__(random_state=random_state)\n",
    "        self.check_greater_or_equal(proportion, \"proportion\", 0)\n",
    "        self.check_greater_or_equal(n_neighbors, \"n_neighbors\", 1)\n",
    "        self.check_n_jobs(n_jobs, 'n_jobs')\n",
    "\n",
    "        self.proportion = proportion\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.nn_params = coalesce(nn_params, {})\n",
    "        self.n_jobs = n_jobs\n",
    "        self.y_index = 16 # X.columns.get_loc('Petting') = 16 \n",
    "        \n",
    "    @ classmethod\n",
    "    def parameter_combinations(cls, raw=False):\n",
    "        \"\"\"\n",
    "        Generates reasonable parameter combinations.\n",
    "\n",
    "        Returns:\n",
    "            list(dict): a list of meaningful parameter combinations\n",
    "        \"\"\"\n",
    "        parameter_combinations = {'proportion': [0.1, 0.25, 0.5, 0.75,\n",
    "                                                 1.0, 1.5, 2.0],\n",
    "                                  'n_neighbors': [3, 5]}\n",
    "        return cls.generate_parameter_combinations(parameter_combinations, raw)\n",
    "\n",
    "    def class_label_statistics(self, y):\n",
    "        \"\"\"\n",
    "        determines class sizes and minority and majority labels\n",
    "        Args:\n",
    "            X (np.array): features\n",
    "            y (np.array): target labels\n",
    "        \"\"\"\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        self.class_stats = dict(zip(unique, counts))\n",
    "        self.min_label = unique[0] if counts[0] < counts[1] else unique[1]\n",
    "        self.maj_label = unique[1] if counts[0] < counts[1] else unique[0]\n",
    "\n",
    "    def generate_samples(self, *, X, X_maj, X_min, minority_indices,\n",
    "                            n_to_sample, maj_indices, min_indices):\n",
    "        \"\"\"\n",
    "        Generate samples\n",
    "\n",
    "        Args:\n",
    "            X (np.array): all training vectors\n",
    "            X_maj (np.array): majority vectors\n",
    "            X_min (np.array): minority vectors\n",
    "            minority_indices (np.array): the minority indices\n",
    "            n_to_sample (int): number of samples to generate\n",
    "            maj_indices (np.array): majority neighborhood structure\n",
    "            min_indices (np.array): minority neighborhood structure\n",
    "\n",
    "        Returns:\n",
    "            np.array: the generated samples\n",
    "        \"\"\"\n",
    "        base_ind = self.random_state.choice(np.arange(len(minority_indices)),\n",
    "                                            n_to_sample)\n",
    "\n",
    "        u = X[minority_indices[base_ind]] # pylint: disable=invalid-name\n",
    "        neigh_ind = self.random_state.choice(np.arange(0, maj_indices.shape[1]),\n",
    "                                             n_to_sample)\n",
    "        v = X_maj[maj_indices[base_ind, neigh_ind]] # pylint: disable=invalid-name\n",
    "        uu = u + self.random_state.random_sample(u.shape) * 0.3 * (u - v) # pylint: disable=invalid-name\n",
    "        min_neigh_ind = self.random_state.choice(np.arange(1, min_indices.shape[1]),\n",
    "                                                 n_to_sample)\n",
    "        x = X_min[min_indices[base_ind, min_neigh_ind]] # pylint: disable=invalid-name\n",
    "        return x + self.random_state.random_sample(x.shape) * 0.5 * (uu - x)\n",
    "\n",
    "    def sampling_algorithm(self, X, y):\n",
    "        \"\"\"\n",
    "        Does the sample generation according to the class parameters.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): training set\n",
    "            y (np.array): target labels\n",
    "\n",
    "        Returns:\n",
    "            (np.ndarray, np.array): the extended training set and target labels\n",
    "        \"\"\"\n",
    "        self.class_label_statistics(y)\n",
    "        n_to_sample = self.det_n_to_sample(self.proportion,\n",
    "                                           self.class_stats[self.maj_label],\n",
    "                                           self.class_stats[self.min_label])\n",
    "        if n_to_sample == 0:\n",
    "            return self.return_copies(X, y, \"Sampling is not needed\")\n",
    "\n",
    "        X_min = X[np.where(y == self.min_label)[0]]\n",
    "        X_maj = X[np.where(y == self.maj_label)[0]]\n",
    "\n",
    "        minority_indices = np.where(y == self.min_label)[0]       \n",
    "\n",
    "        # Nearest neighbors among minority points\n",
    "        nn_params = {**self.nn_params}\n",
    "        nn_params['metric_tensor'] = \\\n",
    "            self.metric_tensor_from_nn_params(nn_params, X, y)\n",
    "\n",
    "        n_neighbors_min = min([len(X_min), self.n_neighbors+1])\n",
    "        nn_min= NearestNeighborsWithMetricTensor(n_neighbors=n_neighbors_min,\n",
    "                                                    n_jobs=self.n_jobs,\n",
    "                                                    **nn_params)\n",
    "        nn_min.fit(X_min)\n",
    "        \n",
    "        min_indices = nn_min.kneighbors(X_min, return_distance=False)\n",
    "        # nearest neighbors among majority points\n",
    "        n_neighbors_maj = min([len(X_maj), self.n_neighbors+1])\n",
    "        nn_maj= NearestNeighborsWithMetricTensor(n_neighbors=n_neighbors_maj,\n",
    "                                                    n_jobs=self.n_jobs,\n",
    "                                                    **nn_params)\n",
    "        nn_maj.fit(X_maj)\n",
    "        maj_indices = nn_maj.kneighbors(X_min, return_distance=False)\n",
    "\n",
    "        samples = self.generate_samples(X=X, X_maj=X_maj, X_min=X_min,\n",
    "                    minority_indices=minority_indices, n_to_sample=n_to_sample,\n",
    "                    maj_indices=maj_indices, min_indices=min_indices)\n",
    "\n",
    "\n",
    "        # generate samples\n",
    "        #samples = []\n",
    "        #for _ in range(n_to_sample):\n",
    "        #    # implementation of Algorithm 1 in the paper\n",
    "        #    random_idx = self.random_state.choice(np.arange(len(minority_indices)))\n",
    "        #    u = X[minority_indices[random_idx]]\n",
    "        #    v = X_maj[self.random_state.choice(maj_indices[random_idx])]\n",
    "        #    dif1 = u - v\n",
    "        #    uu = u + self.random_state.random_sample()*0.3*dif1\n",
    "        #    x = X_min[self.random_state.choice(min_indices[random_idx][1:])]\n",
    "        #    dif2 = uu - x\n",
    "        #    w = x + self.random_state.random_sample()*0.5*dif2\n",
    "        #\n",
    "        #    samples.append(w)\n",
    "\n",
    "        return (np.vstack([X, samples]),\n",
    "                np.hstack([y, np.repeat(self.min_label, len(samples))]))\n",
    "\n",
    "    def get_params(self, deep=False):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            dict: the parameters of the current sampling object\n",
    "        \"\"\"\n",
    "        return {'proportion': self.proportion,\n",
    "                'n_neighbors': self.n_neighbors,\n",
    "                'nn_params': self.nn_params,\n",
    "                'n_jobs': self.n_jobs,\n",
    "                **OverSampling.get_params(self)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bc26493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_out=SMOTE_OUT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "be50046f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 09:54:54,921:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2024-03-19 09:54:54,923:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "2024-03-19 09:54:54,925:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2024-03-19 09:54:54,926:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n"
     ]
    }
   ],
   "source": [
    "oversampled = smote_out.sampling_algorithm(np.array(X),np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bc460f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(oversampled[0], columns= X.keys()) \n",
    "difference = oversampled[1][len(X['Petting']):]\n",
    "df.loc[df.index[-len(difference):], 'Petting'] = difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "33f658d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new generated data into csv file\n",
    "df.to_csv(\"./generated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe5d283",
   "metadata": {},
   "source": [
    "# Smote-out\n",
    "[Before] Petting: 90 / Non-Petting: 10 --> [After] Petting: 90 / Non-Petting: 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "31496086",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"./generated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fc4bd97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=data1\n",
    "y1=data1['Petting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b76fcb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_logger = logger\n",
    "__all__= ['SMOTE_OUT']\n",
    "\n",
    "class SMOTE_OUT1(OverSampling):\n",
    "\n",
    "    categories = [OverSampling.cat_extensive,\n",
    "                  OverSampling.cat_metric_learning]\n",
    "\n",
    "    def __init__(self,\n",
    "                 proportion=1.0, #Since Petting ==1 has 90 data, synthesize non_petting data same number to that\n",
    "                 n_neighbors=2,\n",
    "                 *,\n",
    "                 nn_params=None,\n",
    "                 n_jobs=1,\n",
    "                 random_state=None,\n",
    "                 **_kwargs):\n",
    "        \"\"\"\n",
    "        Constructor of the sampling object\n",
    "\n",
    "        Args:\n",
    "            proportion (float): proportion of the difference of n_maj and n_min\n",
    "                                to sample e.g. 1.0 means that after sampling\n",
    "                                the number of minority samples will be equal to\n",
    "                                the number of majority samples\n",
    "            n_neighbors (int): parameter of the NearestNeighbors component\n",
    "            nn_params (dict): additional parameters for nearest neighbor calculations, any\n",
    "                                parameter NearestNeighbors accepts, and additionally use\n",
    "                                {'metric': 'precomputed', 'metric_learning': '<method>', ...}\n",
    "                                with <method> in 'ITML', 'LSML' to enable the learning of\n",
    "                                the metric to be used for neighborhood calculations\n",
    "            n_jobs (int): number of parallel jobs\n",
    "            random_state (int/RandomState/None): initializer of random_state,\n",
    "                                                    like in sklearn\n",
    "        \"\"\"\n",
    "        super().__init__(random_state=random_state)\n",
    "        self.check_greater_or_equal(proportion, \"proportion\", 0)\n",
    "        self.check_greater_or_equal(n_neighbors, \"n_neighbors\", 1)\n",
    "        self.check_n_jobs(n_jobs, 'n_jobs')\n",
    "\n",
    "        self.proportion = proportion\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.nn_params = coalesce(nn_params, {})\n",
    "        self.n_jobs = n_jobs\n",
    "        self.y_index = 16 # X.columns.get_loc('Petting') = 16 \n",
    "        \n",
    "    @ classmethod\n",
    "    def parameter_combinations(cls, raw=False):\n",
    "        \"\"\"\n",
    "        Generates reasonable parameter combinations.\n",
    "\n",
    "        Returns:\n",
    "            list(dict): a list of meaningful parameter combinations\n",
    "        \"\"\"\n",
    "        parameter_combinations = {'proportion': [0.1, 0.25, 0.5, 0.75,\n",
    "                                                 1.0, 1.5, 2.0],\n",
    "                                  'n_neighbors': [3, 5]}\n",
    "        return cls.generate_parameter_combinations(parameter_combinations, raw)\n",
    "\n",
    "    def class_label_statistics(self, y):\n",
    "        \"\"\"\n",
    "        determines class sizes and minority and majority labels\n",
    "        Args:\n",
    "            X (np.array): features\n",
    "            y (np.array): target labels\n",
    "        \"\"\"\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        self.class_stats = dict(zip(unique, counts))\n",
    "        self.min_label = unique[0] if counts[0] < counts[1] else unique[1]\n",
    "        self.maj_label = unique[1] if counts[0] < counts[1] else unique[0]\n",
    "\n",
    "    def generate_samples(self, *, X, X_maj, X_min, minority_indices,\n",
    "                            n_to_sample, maj_indices, min_indices):\n",
    "        \"\"\"\n",
    "        Generate samples\n",
    "\n",
    "        Args:\n",
    "            X (np.array): all training vectors\n",
    "            X_maj (np.array): majority vectors\n",
    "            X_min (np.array): minority vectors\n",
    "            minority_indices (np.array): the minority indices\n",
    "            n_to_sample (int): number of samples to generate\n",
    "            maj_indices (np.array): majority neighborhood structure\n",
    "            min_indices (np.array): minority neighborhood structure\n",
    "\n",
    "        Returns:\n",
    "            np.array: the generated samples\n",
    "        \"\"\"\n",
    "        base_ind = self.random_state.choice(np.arange(len(minority_indices)),\n",
    "                                            n_to_sample)\n",
    "\n",
    "        u = X[minority_indices[base_ind]] # pylint: disable=invalid-name\n",
    "        neigh_ind = self.random_state.choice(np.arange(0, maj_indices.shape[1]),\n",
    "                                             n_to_sample)\n",
    "        v = X_maj[maj_indices[base_ind, neigh_ind]] # pylint: disable=invalid-name\n",
    "        uu = u + self.random_state.random_sample(u.shape) * 0.3 * (u - v) # pylint: disable=invalid-name\n",
    "        min_neigh_ind = self.random_state.choice(np.arange(1, min_indices.shape[1]),\n",
    "                                                 n_to_sample)\n",
    "        x = X_min[min_indices[base_ind, min_neigh_ind]] # pylint: disable=invalid-name\n",
    "        return x + self.random_state.random_sample(x.shape) * 0.5 * (uu - x)\n",
    "\n",
    "    def sampling_algorithm(self, X, y):\n",
    "        \"\"\"\n",
    "        Does the sample generation according to the class parameters.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): training set\n",
    "            y (np.array): target labels\n",
    "\n",
    "        Returns:\n",
    "            (np.ndarray, np.array): the extended training set and target labels\n",
    "        \"\"\"\n",
    "        # n_to_sample=5\n",
    "\n",
    "        self.class_label_statistics(y)\n",
    "        n_to_sample = self.det_n_to_sample(self.proportion,\n",
    "                                           self.class_stats[self.maj_label],\n",
    "                                           self.class_stats[self.min_label])\n",
    "        if n_to_sample == 0:\n",
    "            return self.return_copies(X, y, \"Sampling is not needed\")\n",
    " \n",
    "        X_min = X[np.where(y == self.min_label)[0]]\n",
    "        X_maj = X[np.where(y == self.maj_label)[0]]\n",
    "\n",
    "        minority_indices = np.where(y == self.min_label)[0]\n",
    "        \n",
    "\n",
    "        # Nearest neighbors among minority points\n",
    "        nn_params = {**self.nn_params}\n",
    "        nn_params['metric_tensor'] = \\\n",
    "            self.metric_tensor_from_nn_params(nn_params, X, y)\n",
    "\n",
    "        n_neighbors_min = min([len(X_min), self.n_neighbors+1])\n",
    "        nn_min= NearestNeighborsWithMetricTensor(n_neighbors=n_neighbors_min,\n",
    "                                                    n_jobs=self.n_jobs,\n",
    "                                                    **nn_params)\n",
    "        nn_min.fit(X_min)\n",
    "        \n",
    "        min_indices = nn_min.kneighbors(X_min, return_distance=False)\n",
    "        \n",
    "        # Nearest neighbors among majority points\n",
    "        n_neighbors_maj = min([len(X_maj), self.n_neighbors+1])\n",
    "        nn_maj= NearestNeighborsWithMetricTensor(n_neighbors=n_neighbors_maj,\n",
    "                                                    n_jobs=self.n_jobs,\n",
    "                                                    **nn_params)\n",
    "        nn_maj.fit(X_maj)\n",
    "        maj_indices = nn_maj.kneighbors(X_min, return_distance=False)\n",
    "\n",
    "        samples = self.generate_samples(X=X, X_maj=X_maj, X_min=X_min,\n",
    "                    minority_indices=minority_indices, n_to_sample=n_to_sample,\n",
    "                    maj_indices=maj_indices, min_indices=min_indices)\n",
    "\n",
    "\n",
    "        # generate samples\n",
    "        #samples = []\n",
    "        #for _ in range(n_to_sample):\n",
    "        #    # implementation of Algorithm 1 in the paper\n",
    "        #    random_idx = self.random_state.choice(np.arange(len(minority_indices)))\n",
    "        #    u = X[minority_indices[random_idx]]\n",
    "        #    v = X_maj[self.random_state.choice(maj_indices[random_idx])]\n",
    "        #    dif1 = u - v\n",
    "        #    uu = u + self.random_state.random_sample()*0.3*dif1\n",
    "        #    x = X_min[self.random_state.choice(min_indices[random_idx][1:])]\n",
    "        #    dif2 = uu - x\n",
    "        #    w = x + self.random_state.random_sample()*0.5*dif2\n",
    "        #\n",
    "        #    samples.append(w)\n",
    "\n",
    "        return (np.vstack([X, samples]),\n",
    "                np.hstack([y, np.repeat(self.min_label, len(samples))]))\n",
    "\n",
    "    def get_params(self, deep=False):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            dict: the parameters of the current sampling object\n",
    "        \"\"\"\n",
    "        return {'proportion': self.proportion,\n",
    "                'n_neighbors': self.n_neighbors,\n",
    "                'nn_params': self.nn_params,\n",
    "                'n_jobs': self.n_jobs,\n",
    "                **OverSampling.get_params(self)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "67254f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 09:54:55,065:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2024-03-19 09:54:55,066:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "2024-03-19 09:54:55,068:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2024-03-19 09:54:55,069:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n"
     ]
    }
   ],
   "source": [
    "smote_out1=SMOTE_OUT1()\n",
    "oversampled1 = smote_out1.sampling_algorithm(np.array(X1),np.array(y1))\n",
    "df1 = pd.DataFrame(oversampled1[0], columns= X1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b191b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference1 = oversampled1[1][len(X1['Petting']):]\n",
    "df1.loc[df1.index[-len(difference1):], 'Petting'] = difference1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e2fd4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result o csv file\n",
    "df1.to_csv(\"./result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a311926",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "18415f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ec4b2c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "82a01372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(data):\n",
    "    \n",
    "    # Split the data into features (X) and target (y)\n",
    "    X = data.drop('Petting', axis=1)\n",
    "    y = data['Petting']\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_pred_prob = rf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calc acc, auc\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    return accuracy, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "89330882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more accurate result, try 5 times\n",
    "acc1,auc1=random_forest(df)\n",
    "acc2,auc2=random_forest(df)\n",
    "acc3,auc3=random_forest(df)\n",
    "acc4,auc4=random_forest(df)\n",
    "acc5,auc5=random_forest(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "89404f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9666666666666666\n",
      "auc: 0.9837098768534528\n"
     ]
    }
   ],
   "source": [
    "acc_avg=(acc1+acc2+acc3+acc4+acc5)/5\n",
    "auc_avg=(auc1+auc2+auc3+auc4+auc5)/5\n",
    "print(\"acc:\", acc_avg)\n",
    "print(\"auc:\", auc_avg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
